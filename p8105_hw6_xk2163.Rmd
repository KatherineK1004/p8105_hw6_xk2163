---
title: "p8105_hw6_xk2163"
author: "Kang"
date: "2024-12-03"
output: 
  github_document
---

```{r message=FALSE}
library(tidyverse)
library(ggplot2)
```

# Problem 2

```{r,warning=FALSE,message=FALSE}
data_df = 
  read_csv("Data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(city_state = paste(city,state, sep = ", "),
         resolved = case_when(
           disposition == "Closed by arrest" ~ 1,
           disposition == "Closed without arrest" ~ 1,
           disposition == "Open/No arrest" ~ 0),
         victim_age = as.numeric(victim_age)) |> 
  filter(!(city %in% 
             c("Dallas", "Phoenix", "Kansas City", "Tulsa")) & 
           (victim_race == "Black" | victim_race == "White")) 
  
```

In the above part, I create a new `city_state` variable by combining the city and state names. Then, I generate a binary `resolved` variable, where homicides marked as "Closed by arrest" or "Closed without arrest" are coded as 1 (resolved), and "Open/No arrest" cases are coded as 0 (unresolved). I also convert the `victim_age` column to a numeric type for further analysis. Lastly, I filter out records from specific cities (Dallas, Phoenix, Kansas City, and Tulsa) due to incomplete race data, and limit the data to cases where the victim's race is either Black or White.

```{r}
data_balti = data_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_model =
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data = data_balti,
    family = binomial)

broom::tidy(baltimore_model) |> 
  mutate(odds_ratio = exp(estimate),   
         conf.low = exp(estimate - 1.96 * std.error),   
         conf.high = exp(estimate + 1.96 * std.error)) |> 
  select(term, estimate, odds_ratio, conf.low, conf.high, p.value) |>
  knitr::kable(
    caption = "Logistic Regression Results for Solving Homicides in Baltimore, MD",
    col.names = c("Term", "Estimate", "Odds Ratio", "Conf. Low", "Conf. High", "P-value"),
    digits = 3)
```

Then, I fit a logistic regression model to predict whether a homicide case is resolved in `Baltimore`, using the victim's age, sex, and race as predictors. After fitting the model, I used `broom::tidy` to organize the model output and calculated the odds ratios and their 95% confidence intervals for each predictor by exponentiating the coefficient estimates and confidence bounds. Finally, I formatted the table to display the term, estimate, odds ratio, confidence intervals, and p-values.

### Explanation of Results:

- **Intercept**: The baseline odds of a case being resolved when all predictors are at their reference levels. The odds ratio is 1.942, indicating that, on average, cases have nearly twice the odds of being resolved at the baseline level.
- **victim_age**: The odds ratio of 0.995 suggests that each additional year of age slightly decreases the odds of resolution, though this effect is not statistically significant (p = 0.11).
- **victim_sexMale**: The odds ratio of 0.355 indicates that cases involving male victims have significantly lower odds (around 64.5% lower) of being resolved compared to female victims, with a p-value of 0.00.
- **victim_raceWhite**: The odds ratio of 2.459 implies that cases involving White victims have significantly higher odds of being resolved (about 146% higher) than cases with Black victims, with a p-value of 0.00.

These results highlight significant differences in the resolution rates of homicides based on victim characteristics, particularly victim sex and race.

# Problem 3

```{r, message=FALSE}
data_df_2 = 
  read_csv("Data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(case_when(
      babysex == 1 ~ "Male",
      babysex == 2 ~ "Female")),
    
    frace = factor(case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown")),
    
    mrace = factor(case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other")),
    
    malform = factor(case_when(
      malform == 0 ~ "Absent",
      malform == 1 ~ "Present")))

```

For the question 3,I transformed several variables into factors with descriptive labels:

- **babysex**: Converted to a factor with levels "Male" and "Female" based on numerical codes.
- **frace**: Converted to a factor representing the father's race, with labels such as "White," "Black," "Asian," "Puerto Rican," "Other," and "Unknown."
- **mrace**: Converted to a factor representing the mother's race, with similar race labels as for the father's race.
- **malform**: Converted to a factor indicating the presence or absence of malformations in the baby, labeled as "Absent" and "Present".

```{r}
birthweight_model1 =
  lm(bwt ~ bhead + blength + babysex + gaweeks + momage + mrace +
       frace + delwt + smoken + malform, data = data_df_2)

data_df_2_diag = data_df_2 |> 
  modelr::add_predictions(birthweight_model1, var = "predicted_bwt") |> 
  modelr::add_residuals(birthweight_model1, var = "residuals_bwt")

ggplot(data_df_2_diag, aes(x = predicted_bwt, y = residuals_bwt)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals",
    title = "Residual Plot for Birthweight Model"
  ) + theme_minimal()
```

After preprocessing the given data, I also make a residual plot.

It shows the residuals against the predicted birthweight values. The dashed red line at zero represents the ideal line where the modelâ€™s predictions perfectly match the actual values. Here are some observations:

* *Centering Around Zero*: Most of the residuals are centered around the red line at zero, which suggests that the model does not systematically overpredict or underpredict birthweight across the range of fitted values.

* *Variance of Residuals*: The residuals exhibit a pattern where the spread seems relatively consistent across the fitted values, although there are some larger residuals for extreme fitted values. This suggests approximate homoscedasticity (constant variance), an assumption of linear regression. However, some extreme values on the left and right may indicate areas where the model is less accurate.

* *Outliers*: There are a few large residuals far from zero, suggesting that the model does not capture some variability in birthweight for certain cases. These could be outliers or indicate potential non-linear effects not captured by the model.

Overall, the residual plot indicates that the model is reasonably well-fitted, though further investigation of the outliers or potential interactions and non-linear relationships might improve model performance.