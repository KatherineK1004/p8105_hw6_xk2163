---
title: "p8105_hw6_xk2163"
author: "Kang"
date: "2024-12-03"
output: 
  github_document
---

```{r message=FALSE}
library(tidyverse)
library(ggplot2)
```

# Problem 2

```{r,warning=FALSE,message=FALSE}
data_df = 
  read_csv("Data/homicide-data.csv") |> 
  janitor::clean_names() |> 
  mutate(city_state = paste(city,state, sep = ", "),
         resolved = case_when(
           disposition == "Closed by arrest" ~ 1,
           disposition == "Closed without arrest" ~ 1,
           disposition == "Open/No arrest" ~ 0),
         victim_age = as.numeric(victim_age)) |> 
  filter(!(city %in% 
             c("Dallas", "Phoenix", "Kansas City", "Tulsa")) & 
           (victim_race == "Black" | victim_race == "White")) 
  
```

In the above part, I create a new `city_state` variable by combining the city and state names. Then, I generate a binary `resolved` variable, where homicides marked as "Closed by arrest" or "Closed without arrest" are coded as 1 (resolved), and "Open/No arrest" cases are coded as 0 (unresolved). I also convert the `victim_age` column to a numeric type for further analysis. Lastly, I filter out records from specific cities (Dallas, Phoenix, Kansas City, and Tulsa) due to incomplete race data, and limit the data to cases where the victim's race is either Black or White.

```{r}
data_balti = data_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_model =
  glm(
    resolved ~ victim_age + victim_sex + victim_race,
    data = data_balti,
    family = binomial)

broom::tidy(baltimore_model) |> 
  mutate(odds_ratio = exp(estimate),   
         conf.low = exp(estimate - 1.96 * std.error),   
         conf.high = exp(estimate + 1.96 * std.error)) |> 
  select(term, estimate, odds_ratio, conf.low, conf.high, p.value) |>
  knitr::kable(
    caption = "Logistic Regression Results for Solving Homicides in Baltimore, MD",
    col.names = c("Term", "Estimate", "Odds Ratio", "Conf. Low", "Conf. High", "P-value"),
    digits = 3)
```

Then, I fit a logistic regression model to predict whether a homicide case is resolved in `Baltimore`, using the victim's age, sex, and race as predictors. After fitting the model, I used `broom::tidy` to organize the model output and calculated the odds ratios and their 95% confidence intervals for each predictor by exponentiating the coefficient estimates and confidence bounds. Finally, I formatted the table to display the term, estimate, odds ratio, confidence intervals, and p-values.

### Explanation of Results:

- **Intercept**: The baseline odds of a case being resolved when all predictors are at their reference levels. The odds ratio is 1.942, indicating that, on average, cases have nearly twice the odds of being resolved at the baseline level.
- **victim_age**: The odds ratio of 0.995 suggests that each additional year of age slightly decreases the odds of resolution, though this effect is not statistically significant (p = 0.11).
- **victim_sexMale**: The odds ratio of 0.355 indicates that cases involving male victims have significantly lower odds (around 64.5% lower) of being resolved compared to female victims, with a p-value of 0.00.
- **victim_raceWhite**: The odds ratio of 2.459 implies that cases involving White victims have significantly higher odds of being resolved (about 146% higher) than cases with Black victims, with a p-value of 0.00.

These results highlight significant differences in the resolution rates of homicides based on victim characteristics, particularly victim sex and race.

```{r}
nested_data = 
  data_df |>
  group_by(city_state) |>
  nest()

run_logistic_model = function(data) {
  glm(resolved ~ victim_age + victim_sex + victim_race,
      data = data, family = binomial)}

model_results = 
  nested_data |>
  mutate(
    model = map(data, run_logistic_model),
    tidied = map(model, broom::tidy)) |>
  unnest(tidied)                                               

results_sex_or = 
  model_results |>
  filter(term == "victim_sexMale") |>                         
  mutate(
    odds_ratio = exp(estimate),                                
    conf.low = exp(estimate - 1.96 * std.error),               
    conf.high = exp(estimate + 1.96 * std.error)) 

results_sex_or |>
  select(city_state,estimate,odds_ratio, conf.low, conf.high,p.value) |> 
  knitr::kable(
    caption = "Logistic Regression Results",
    col.names = c("Location", "Estimate", "Odds Ratio",
                  "Conf. Low", "Conf. High", "P-value"),
    digits = 3)
```

The coefficients of the term called `victim_sexMale` in each city are shown above. To make it more clear, I also make a plot in the following step.

```{r}
results_sex_or = results_sex_or |> 
  arrange(odds_ratio) |> 
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(results_sex_or, aes(x = city_state, y = odds_ratio)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    x = "City",
    y = "Odds Ratio (Male vs Female)",
    title = "Adjusted OR for Solving Homicides (Male vs Female by City)",
    subtitle = "Odds Ratios and 95% CI for each city"
  ) +
  theme_minimal()+
  theme(axis.text.y = element_text(size = 6))
```

The graph shows the adjusted odds ratios (ORs) for solving homicide cases, comparing male to female victims across various cities. An odds ratio below 1 indicates that cases involving male victims are less likely to be resolved than those involving female victims in that city, while an odds ratio above 1 would suggest the opposite.

Many cities have ORs below 1, indicating that male victims' cases are less likely to be resolved compared to female victims in those locations. Some cities have wider confidence intervals, suggesting more variability or fewer cases, which makes the OR estimate less precise. In cities where the confidence interval crosses 1, there is no statistically significant difference in resolution rates between male and female victims.

Overall, the plot highlights a trend across several cities where homicides involving male victims tend to be resolved at a lower rate than those involving female victims, though the extent of this disparity varies by city.

# Problem 3

```{r, message=FALSE}
data_df_2 = 
  read_csv("Data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(case_when(
      babysex == 1 ~ "Male",
      babysex == 2 ~ "Female")),
    
    frace = factor(case_when(
      frace == 1 ~ "White",
      frace == 2 ~ "Black",
      frace == 3 ~ "Asian",
      frace == 4 ~ "Puerto Rican",
      frace == 8 ~ "Other",
      frace == 9 ~ "Unknown")),
    
    mrace = factor(case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other")),
    
    malform = factor(case_when(
      malform == 0 ~ "Absent",
      malform == 1 ~ "Present")))

```

For the question 3,I transformed several variables into factors with descriptive labels:

- **babysex**: Converted to a factor with levels "Male" and "Female" based on numerical codes.
- **frace**: Converted to a factor representing the father's race, with labels such as "White," "Black," "Asian," "Puerto Rican," "Other," and "Unknown."
- **mrace**: Converted to a factor representing the mother's race, with similar race labels as for the father's race.
- **malform**: Converted to a factor indicating the presence or absence of malformations in the baby, labeled as "Absent" and "Present".

```{r}
birthweight_model1 =
  lm(bwt ~ bhead + blength + babysex + gaweeks + momage + mrace +
       frace + delwt + smoken + malform, data = data_df_2)

data_df_2_diag = data_df_2 |> 
  modelr::add_predictions(birthweight_model1, var = "predicted_bwt") |> 
  modelr::add_residuals(birthweight_model1, var = "residuals_bwt")

ggplot(data_df_2_diag, aes(x = predicted_bwt, y = residuals_bwt)) +
  geom_point(alpha = 0.6) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals",
    title = "Residual Plot for Birthweight Model"
  ) + theme_minimal()
```

After preprocessing the given data, I also make a residual plot.

It shows the residuals against the predicted birthweight values. The dashed red line at zero represents the ideal line where the modelâ€™s predictions perfectly match the actual values. Here are some observations:

* *Centering Around Zero*: Most of the residuals are centered around the red line at zero, which suggests that the model does not systematically overpredict or underpredict birthweight across the range of fitted values.

* *Variance of Residuals*: The residuals exhibit a pattern where the spread seems relatively consistent across the fitted values, although there are some larger residuals for extreme fitted values. This suggests approximate homoscedasticity (constant variance), an assumption of linear regression. However, some extreme values on the left and right may indicate areas where the model is less accurate.

* *Outliers*: There are a few large residuals far from zero, suggesting that the model does not capture some variability in birthweight for certain cases. These could be outliers or indicate potential non-linear effects not captured by the model.

Overall, the residual plot indicates that the model is reasonably well-fitted, though further investigation of the outliers or potential interactions and non-linear relationships might improve model performance.

```{r}

model_formulas = list(
  linear = "bwt ~ blength + gaweeks",
  complex = "bwt ~ bhead * blength * babysex",
  proposed = "bwt ~ bhead + blength + babysex + gaweeks + momage + mrace + frace + delwt + smoken + malform"
)

set.seed(123)
cv_df = modelr::crossv_mc(data_df_2, n = 10) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df = cv_df |>
  mutate(
    linear_mod = map(train, ~ lm(as.formula(model_formulas$linear), data = .x)),
    complex_mod = map(train, ~ lm(as.formula(model_formulas$complex), data = .x)),
    proposed_mod = map(train, ~ lm(as.formula(model_formulas$proposed), data = .x)),
    rmse_linear = map2_dbl(linear_mod, test, ~ sqrt(mean((.y$bwt - predict(.x, newdata = .y))^2))),
    rmse_complex = map2_dbl(complex_mod, test, ~ sqrt(mean((.y$bwt - predict(.x, newdata = .y))^2))),
    rmse_proposed = map2_dbl(proposed_mod, test, ~ sqrt(mean((.y$bwt - predict(.x, newdata = .y))^2))) )

cv_df |>
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") |>
  mutate(model = forcats::fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Cross-Validated RMSE Distribution by Model",
    x = "Model",
    y = "RMSE")

```

To make the comparison more clear, I also made a plot for comparing the performance of different model.

It mainly shows that the proposed model has the lowest and most consistent RMSE, making it the most accurate for predicting birthweight. The complex model performs better than the linear model but not as well as the proposed model. The linear model has the highest and most variable RMSE, indicating the least accurate performance.